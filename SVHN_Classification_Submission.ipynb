{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "SVHN Classification Submission.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Dh4TDX2uAXvG",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Street View House Numbers Classification\n"
      ]
    },
    {
      "metadata": {
        "id": "qA7zos6Vz2BF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import random\n",
        "import numpy as np\n",
        "import scipy.io\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "import keras\n",
        "from keras.models import Sequential\n",
        "from keras.layers import *\n",
        "from keras.utils import to_categorical\n",
        "from keras.constraints import max_norm\n",
        "import sklearn.model_selection\n",
        "from keras.preprocessing.image import ImageDataGenerator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zDLCJ2ZsBP28",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Loading All Three Sets"
      ]
    },
    {
      "metadata": {
        "id": "k53yyJmu1Do4",
        "colab_type": "code",
        "outputId": "c6998019-5ab6-40c5-a778-8a9aa03c6f5b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "train_mat = keras.utils.get_file(\"train_32x32.mat\", \"https://s3-ap-southeast-1.amazonaws.com/deeplearning-iap-material/train_32x32.mat\")\n",
        "test_mat = keras.utils.get_file(\"test_32x32.mat\", \"https://s3-ap-southeast-1.amazonaws.com/deeplearning-iap-material/test_32x32.mat\")\n",
        "extra_mat = keras.utils.get_file(\"extra_32x32.mat\", \"http://ufldl.stanford.edu/housenumbers/extra_32x32.mat\")\n",
        "train_array = scipy.io.loadmat(train_mat)\n",
        "train_array[\"X\"].shape, train_array[\"y\"].shape\n",
        "test_array = scipy.io.loadmat(test_mat)\n",
        "test_array[\"X\"].shape, test_array[\"y\"].shape\n",
        "extra_array = scipy.io.loadmat(extra_mat)\n",
        "extra_array[\"X\"].shape, extra_array[\"y\"].shape\n",
        "print(\"Datasets loaded\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Datasets loaded\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qv1oeVzzp3ow",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Preprocessing Data"
      ]
    },
    {
      "metadata": {
        "id": "tZwjMcUDA-Y-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Training set and Extra set were combined together for training data.\n",
        "\n",
        "Observations:\n",
        "1. Using Extra set for training only with Training set for validation showed reduced accuracy compared to combined set and randomly setting validation set through sklearn function\n",
        "2. Using combined set for traning resulted in higher accuracy than just using training set or extra set only, as expected\n",
        "\n",
        "Crashes due to memory overflow occured in these scenarios:\n",
        "1. ImageDataGenerator used on Combined/Extra set\n",
        "2. Image augmentation through Scipy on any set\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "oDxs9y1Bqf3I",
        "colab_type": "code",
        "outputId": "609e652d-9149-4b55-bfa5-313831f530e7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "cell_type": "code",
      "source": [
        "num_images = extra_array[\"X\"].shape[-1] \n",
        "list_labels = extra_array[\"y\"].reshape((num_images)) \n",
        "list_labels_train = train_array[\"y\"].reshape((73257))\n",
        "list_labels = np.append(list_labels , list_labels_train)\n",
        "list_images = []\n",
        "\n",
        "for i in range(num_images):\n",
        "    image = extra_array[\"X\"][:,:,:,i].reshape((32,32,3))\n",
        "    list_images.append(image)\n",
        "    \n",
        "for i in range(73257):\n",
        "    image = train_array[\"X\"][:,:,:,i].reshape((32,32,3))\n",
        "    list_images.append(image)\n",
        "    \n",
        "list_labels = np.asarray(list_labels, dtype='int32')\n",
        "list_images = np.asarray(list_images)\n",
        "print(\"Data formatted for Keras\")\n",
        "\n",
        "classes = list(set(list_labels))\n",
        "num_classes = len(classes)\n",
        "print(\"Classes set\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Data formatted for Keras\n",
            "Classes set\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "cvL_9QpBqYGj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## **Train-Validation Split Set**"
      ]
    },
    {
      "metadata": {
        "id": "yvXdW9pjqZBW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Several split ratios were tested: 0.5, 0.2, 0.1, 0.05. For combined set, all ratios did not result in any significant changes (all around 95%) in accuracy except 0.05 which achieved 97% accuracy on average.\n",
        "\n",
        "0.05 was chosen as combined set was already large enough, and 0.05 of the combined set should be able to provide enough variance of data compared to test set. "
      ]
    },
    {
      "metadata": {
        "id": "tdP7TEdsrNSh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X_train, X_val, y_train, y_val = sklearn.model_selection.train_test_split(list_images, list_labels, test_size=0.05)\n",
        "y_train = to_categorical(y_train)\n",
        "y_val = to_categorical(y_val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CJDcm5grrCDk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Build a CNN in Keras\n",
        "\n",
        "Model was modifed to increase kernel size to 5, added in max normalisation for kernel constraint, and added extra dropout layers to regularise the model as it was observed to be overfitting before."
      ]
    },
    {
      "metadata": {
        "id": "x0XQsPPQrJi-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(96, kernel_size=7, activation='relu', input_shape=(32,32,3), strides= 2, kernel_constraint=max_norm(4.), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides= 2))\n",
        "model.add(Dropout(0.1))\n",
        "\n",
        "model.add(Conv2D(128, kernel_size=7, activation='relu', strides= 1, kernel_constraint=max_norm(4.), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides= 2))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Conv2D(256, kernel_size=7, activation='relu', strides= 1, kernel_constraint=max_norm(4.), padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(MaxPooling2D(pool_size=(3,3), strides= 2))\n",
        "model.add(Dropout(0.25))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(2048, activation='relu', kernel_constraint=max_norm(2.)))\n",
        "model.add(Dropout(0.25))\n",
        "model.add(Dense(2048, activation='relu', kernel_constraint=max_norm(2.)))\n",
        "model.add(Dropout(0.5))\n",
        "model.add(Dense(11, activation='softmax', kernel_constraint=max_norm(2.)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "s6ajvgp_CwvX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Optimizer and Compilation"
      ]
    },
    {
      "metadata": {
        "id": "KyPAOEYYqvnb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Stochastic gradient descent optimiser with settings as given in the AutoAugment paper, except for the decay in learning rate. "
      ]
    },
    {
      "metadata": {
        "id": "nrxMjfRXrlf5",
        "colab_type": "code",
        "outputId": "24d70ed0-24d9-4ffe-ee6e-fb2acda765f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 791
        }
      },
      "cell_type": "code",
      "source": [
        "sgd = keras.optimizers.SGD(lr=0.01, momentum=0.9, decay=0.0, nesterov=True)\n",
        "model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['acc'])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d_7 (Conv2D)            (None, 16, 16, 96)        14208     \n",
            "_________________________________________________________________\n",
            "batch_normalization_7 (Batch (None, 16, 16, 96)        384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_7 (MaxPooling2 (None, 7, 7, 96)          0         \n",
            "_________________________________________________________________\n",
            "dropout_11 (Dropout)         (None, 7, 7, 96)          0         \n",
            "_________________________________________________________________\n",
            "conv2d_8 (Conv2D)            (None, 7, 7, 128)         602240    \n",
            "_________________________________________________________________\n",
            "batch_normalization_8 (Batch (None, 7, 7, 128)         512       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_8 (MaxPooling2 (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "dropout_12 (Dropout)         (None, 3, 3, 128)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_9 (Conv2D)            (None, 3, 3, 256)         1605888   \n",
            "_________________________________________________________________\n",
            "batch_normalization_9 (Batch (None, 3, 3, 256)         1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_9 (MaxPooling2 (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "dropout_13 (Dropout)         (None, 1, 1, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_3 (Flatten)          (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 2048)              526336    \n",
            "_________________________________________________________________\n",
            "dropout_14 (Dropout)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 2048)              4196352   \n",
            "_________________________________________________________________\n",
            "dropout_15 (Dropout)         (None, 2048)              0         \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 11)                22539     \n",
            "=================================================================\n",
            "Total params: 6,969,483\n",
            "Trainable params: 6,968,523\n",
            "Non-trainable params: 960\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "y3IU8yRkq3UX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Structure Visualisation"
      ]
    },
    {
      "metadata": {
        "id": "AYdbyExtwOje",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "SVG(model_to_dot(model).create(prog='dot', format='svg'))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "b61YekXVBWby",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Model w/o Generator\n"
      ]
    },
    {
      "metadata": {
        "id": "26PLi69rrB2Z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Please run it for around 15+ epochs to achieve 97% accuracy on average. Highest accuracy achieved was 97.44%."
      ]
    },
    {
      "metadata": {
        "id": "Gww9oWR3uVvy",
        "colab_type": "code",
        "outputId": "b8a5ab8c-0cfd-44cb-9788-1f7d5dc619f6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        }
      },
      "cell_type": "code",
      "source": [
        "#early = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
        "print(\"Training Progress:\")\n",
        "model_log = model.fit(X_train, y_train, batch_size=128, epochs=10, validation_data=[X_val, y_val], )\n",
        "#model.fit_generator(datagen.flow(X_train, y_train, batch_size=128), steps_per_epoch=len(X_train) // 128, epochs=2,             \n",
        "                 #  validation_data=(X_val, y_val),validation_steps=X_train.shape[0] // 128,)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Progress:\n",
            "Train on 574168 samples, validate on 30220 samples\n",
            "Epoch 1/10\n",
            "574168/574168 [==============================] - 181s 316us/step - loss: 0.3652 - acc: 0.8847 - val_loss: 0.1632 - val_acc: 0.9503\n",
            "Epoch 2/10\n",
            "574168/574168 [==============================] - 177s 309us/step - loss: 0.1750 - acc: 0.9480 - val_loss: 0.1284 - val_acc: 0.9614\n",
            "Epoch 3/10\n",
            "574168/574168 [==============================] - 177s 309us/step - loss: 0.1455 - acc: 0.9573 - val_loss: 0.1132 - val_acc: 0.9672\n",
            "Epoch 4/10\n",
            "574168/574168 [==============================] - 179s 311us/step - loss: 0.1301 - acc: 0.9622 - val_loss: 0.1089 - val_acc: 0.9679\n",
            "Epoch 5/10\n",
            "574168/574168 [==============================] - 178s 310us/step - loss: 0.1197 - acc: 0.9652 - val_loss: 0.1075 - val_acc: 0.9689\n",
            "Epoch 6/10\n",
            "574168/574168 [==============================] - 178s 310us/step - loss: 0.1118 - acc: 0.9676 - val_loss: 0.1044 - val_acc: 0.9703\n",
            "Epoch 7/10\n",
            "574168/574168 [==============================] - 178s 310us/step - loss: 0.1071 - acc: 0.9689 - val_loss: 0.0938 - val_acc: 0.9732\n",
            "Epoch 8/10\n",
            "574168/574168 [==============================] - 178s 310us/step - loss: 0.1000 - acc: 0.9710 - val_loss: 0.0973 - val_acc: 0.9720\n",
            "Epoch 9/10\n",
            "574168/574168 [==============================] - 178s 310us/step - loss: 0.0963 - acc: 0.9722 - val_loss: 0.0880 - val_acc: 0.9751\n",
            "Epoch 10/10\n",
            "574168/574168 [==============================] - 179s 311us/step - loss: 0.0924 - acc: 0.9732 - val_loss: 0.0889 - val_acc: 0.9750\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Sasc2ms8rVmr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training Model w Generator\n",
        "(Turned Off for final submission) Not using generator for final submission as it will crash on combined set and does not contribute significantly to the accuracy."
      ]
    },
    {
      "metadata": {
        "id": "60GU5wqbrm6Z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#early = keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=0.001, patience=5, verbose=1, mode='min', baseline=None, restore_best_weights=False)\n",
        "#datagen = ImageDataGenerator(\n",
        "    #featurewise_center=True,\n",
        "    #featurewise_std_normalization=True,\n",
        "    #rotation_range=20,\n",
        "    #width_shift_range=0.2,\n",
        "    #height_shift_range=0.2,\n",
        "    #horizontal_flip=True)  \n",
        "#datagen.fit(X_train)\n",
        "#print(\"Training Progress:\")\n",
        "#model_log = model.fit_generator(datagen.flow(X_train, y_train, batch_size=128), steps_per_epoch=len(X_train) // 128, epochs=2,             \n",
        "                 #  validation_data=(X_val, y_val),validation_steps=X_train.shape[0] // 128,)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GHb2zxwfrqP2",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Saving and Downloading Trained Model"
      ]
    },
    {
      "metadata": {
        "id": "Ycjm7iBMrsa-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Saving model"
      ]
    },
    {
      "metadata": {
        "id": "dXc4zlSNrp0W",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model.save(\"model.h5\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "D7FsZNAprt-v",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Downloading (Does not work sometimes due to server timeout, download through sidebar instead)"
      ]
    },
    {
      "metadata": {
        "id": "eXhgZzUFruJr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_COMKSf8rzSA",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Training History"
      ]
    },
    {
      "metadata": {
        "id": "X-o_rPtsu5xj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.plot(model_log.history['acc'])\n",
        "plt.plot(model_log.history['val_acc'])\n",
        "plt.title('Accuracy (Higher Better)')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()\n",
        "\n",
        "plt.plot(model_log.history['loss'])\n",
        "plt.plot(model_log.history['val_loss'])\n",
        "plt.title('Loss (Lower Better)')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "-vN9AkrXBbwF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Evaluation (Validation Set)"
      ]
    },
    {
      "metadata": {
        "id": "ah3lbd79wh4z",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "import itertools, pickle\n",
        "\n",
        "classes = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"]\n",
        "\n",
        "y_val_index = np.argmax(y_val, axis=1) # Convert one-hot to index\n",
        "y_pred = model.predict(X_val)\n",
        "y_pred_class = np.argmax(y_pred,axis=1)\n",
        "print(classification_report(y_val_index, y_pred_class, target_names=classes))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wpbixeUPwyuu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plt.style.use('seaborn-dark')\n",
        "def plot_confusion_matrix(cm, labels,\n",
        "                          normalize=True,\n",
        "                          title='Confusion Matrix (Validation Set)',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix.\n",
        "    Normalization can be applied by setting `normalize=True`.\n",
        "    \"\"\"\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "        #print(\"Normalized confusion matrix\")\n",
        "    else:\n",
        "        #print('Confusion matrix, without normalization')\n",
        "        pass\n",
        "\n",
        "    #print(cm)\n",
        "\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(labels))\n",
        "    plt.xticks(tick_marks, labels, rotation=45)\n",
        "    plt.yticks(tick_marks, labels)\n",
        "\n",
        "    fmt = '.2f' if normalize else 'd'\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, format(cm[i, j], fmt),\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "\n",
        "plt.figure(figsize=(14,7))\n",
        "cnf_matrix = confusion_matrix(y_val_index, y_pred_class)\n",
        "cnf_matrix = confusion_matrix(y_val_index, y_pred_class)\n",
        "plot_confusion_matrix(cnf_matrix, labels=classes)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "An3kbc35DPZb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Running on the Test Set"
      ]
    },
    {
      "metadata": {
        "id": "4xWt_ODkD3_K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "99831a0c-a067-4979-fdd1-f7718a8c077d"
      },
      "cell_type": "code",
      "source": [
        "# load Keras model from file\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "model = load_model(\"model.h5\")\n",
        "\n",
        "classes = [\"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\", \"8\", \"9\", \"10\"]"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "g73EAQ46DRjd",
        "colab_type": "code",
        "outputId": "350b0b17-10a2-4c88-97be-837f617986dd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 89
        }
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "test_array = scipy.io.loadmat(test_mat)\n",
        "print(test_array.keys())\n",
        "\n",
        "print(\"Test set has the following shape:\")\n",
        "test_array[\"X\"].shape, test_array[\"y\"].shape\n",
        "\n",
        "num_images = test_array[\"y\"].shape[0]\n",
        "\n",
        "test_labels = test_array[\"y\"].reshape((num_images))\n",
        "test_images = []\n",
        "\n",
        "for i in range(num_images):\n",
        "    image = test_array[\"X\"][:,:,:,i].reshape((32,32,3))\n",
        "    test_images.append(image)\n",
        "    \n",
        "test_labels = np.asarray(test_labels, dtype='int32')\n",
        "test_images = np.asarray(test_images)\n",
        "\n",
        "print(\"test_images:\", test_images.shape)\n",
        "\n",
        "test_labels = to_categorical(test_labels)\n",
        "\n",
        "test_labels_index = np.argmax(test_labels, axis=1)\n",
        "test_preds = model.predict(test_images)\n",
        "test_preds_class = np.argmax(test_preds,axis=1)\n",
        "print(\"Test set accuracy score:\", accuracy_score(test_labels_index, test_preds_class))"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['__header__', '__version__', '__globals__', 'X', 'y'])\n",
            "Test set has the following shape:\n",
            "test_images: (26032, 32, 32, 3)\n",
            "Test set accuracy score: 0.9744161032575291\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "qR2J2_YPsCHD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Submission by Pye Sone Kyaw for SUTD AI Challenge 2019\n",
        "Last Modified 21/01/2019."
      ]
    }
  ]
}
